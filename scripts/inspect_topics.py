import csv
import re
import logging
import pickle
import json
import argparse
import gensim
from gensim.corpora.dictionary import Dictionary
from gensim.models.ldamodel import LdaModel
import gensim.parsing.preprocessing as gpp

logging.basicConfig(level=logging.INFO)

parser = argparse.ArgumentParser()
#parser.add_argument(
 #   "--model",
  #  dest="model",
   # required=True,
   # help="Model file generated by training script.")

parser.add_argument(
    "--input_file",
    dest="data",
    help="Data file model will be applied to."
)

parser.add_argument(
    "--output_file",
    dest="output",
    help="Counts output file."
)

parser.add_argument(
    "--topic_of_interest",
    dest="topic_of_interest",
    type = int, 
    help="topic you want to look at"
)

args = parser.parse_args()

csv.field_size_limit(1000000000)

#with open(args.model, "rb") as ifd:
 #   model = pickle.loads(ifd.read())

#num_topics = model.num_topics

#output = model.show_topics(num_topics = num_topics, num_words = 25, formatted = False)

dictionary_list = []

#might need to switch back and forth between jsonl and json 


with open(args.data, "r") as rd:
    for x in rd: 
        dictionary = json.loads(x)
        dictionary_list.append(dictionary)

document_topic_probs = []
    
for doc in dictionary_list:
    #for doc in entry:
    topic_prob = next((prob for topic, prob in doc["document_topics"] if topic == args.topic_of_interest), 0.0)
    new_doc = {}
    for key in doc.keys():
        if key != "topics_for_word_phi":
            if key != "topics_for_word":
                if key != "sub_doc_bow_dict":
                    new_doc[key] = doc[key] 
    document_topic_probs.append((new_doc, topic_prob))

sorted_documents = sorted(document_topic_probs, key=lambda x: x[1], reverse=True)

top_20_documents = sorted_documents[:1484]


with open( args.output, "w") as out_file:
        json.dump(top_20_documents, out_file)
